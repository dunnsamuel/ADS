---
title: "Tidying Data in R"
author: "Sam Dunn"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```


```{r libraries, include=FALSE, warning=FALSE,message=FALSE}
library(tidyr)
library(dplyr)
library(broom)
```

Below we read in data from the website. Use square brackets around ahyperlink to make it a hyperlink in markdown. [Mike Byerly. 2016. Alaska commercial salmon catches by management region (1886- 1997). Gulf of Alaska Data Portal. df35b.304.2.] (https://knb.ecoinformatics.org/#view/df35b.304.2)
```{r Load Data }
catch_df <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1",method = "libcurl"),stringsAsFactors = FALSE) #read in data from site
head(catch_df)

```

```{r eval=FALSE, include=FALSE}
library(RSQLite)
data(mtcars)
cars.df<-mtcars
conn <- dbConnect(SQLite(),'cars.df')
#dbWriteTable(conn, "cars", mtcars)
dbListTables(conn)
dbListFields(conn, "cars")
```
```{r eval=FALSE, include=FALSE}
efficient.df<-dbGetQuery(conn, "SELECT * FROM cars WHERE mpg > 20")

```


keyobard shortcut  ctrl+shift+m => %>% 

Go back to using catch df

startswith, endswith, contains  in select command
```{r Pipe Operators}
catch_df<-catch_df %>% 
  select(-All,-notesRegCode)

```


```{r}
catch_df<-catch_df %>% 
  gather(key="species",value="catch", -Region, -Year) #tranposes df
```
Exlude grouping variables so they dont get transposed...exclude sing "-"


Rename a column
```{r}
catch_df<-catch_df %>% 
  rename(catch_thousands=catch)# %>% #new name=old name
  
  
  
```

```{r}
catch_integers<-as.integer(catch_df$catch_thousands)
i=which(is.na(catch_integers)=="TRUE")

catch_df$catch_thousands[i]
```


```{r}
catch_df <-catch_df %>% 
  mutate(catch_thousands=ifelse(catch_thousands=="I",1,catch_thousands)) %>% #conditional test to rename bad value
  mutate(catch_thousands=as.integer(catch_thousands))%>% 
  rename(catchTHOUSADS=catch_thousands)
  
head(catch_df)  
```

#Split , Apply Combine
```{r}
catch_summarised<-catch_df %>% 
  group_by(Region) %>% 
  summarise(catch_mean=mean(catchTHOUSADS))

catch_summarised
```

```{r}
catch_range<-catch_df %>% 
  group_by(Region,Year,species) %>% 
  summarise(catchlow=range(catchTHOUSADS)[1],
            catchhigh=range(catchTHOUSADS)[2],
            catchmed=median(catchTHOUSADS),
            numobs=n()) %>% filter(species=="Chinook") %>% 
  arrange(desc(Year))
catch_range
```



```{r}
catch_aov<-catch_df %>% 
  group_by(Year) %>% 
  do(tidy(aov(data=.,catchTHOUSADS~species))) %>% 
  filter(Year<="1997" & Year>="1990")

catch_aov
```

##Joins##
Left joins return all left columns and any matching right columns that have matching key.  Have a key for every table!  In this case it is our region code column.  Left joins are the standrad case for joins....under rare circumstancs are Right or full joins done.
```{r}
regdef<-read.csv("df35b.303.1.csv",stringsAsFactors = F)
regdef<-regdef %>% 
  select(code,mgmtArea) %>% 
  rename(Region=code)

joined_tab<-left_join(catch_df,regdef, by="Region") #left join!  
```

c() is the *concatenator* function. Instead  renaming code to Region like I did I could list both keys in the same order as the arguments in the join.  c("Region"="code")

# Visulaization#
GGPlot and leaflet for plots and maps, respectively.  Related question....how do I use bibtex files in markdown?  W're building a webpage!  Using github as the host.  On gthub save a file called index.html and index.rmd .  Go to github settings and find the github pages option.  Set to master and wait for page to render.  Link tot he page will appear eventually. DON'T SET A THEME FOR TH LOVE OF GOD


```{r}
suppressPackageStartupMessages({
  library(leaflet)
  library(dplyr)
  library(tidyr)
  library(ggplot2)
  library(DT)
})
```


The following block allows for the data to only be downloaded once.  It tries to load from a local spot and then goes to the website only if it fails.  SHould save time for large datasets.
```{r}
data_url <- "https://knb.ecoinformatics.org/knb/d1/mn/v2/object/knb.92020.1"
# data_url <- "https://knb.ecoinformatics.org/knb/d1/mn/v2/object/urn%3Auuid%3Af119a05b-bbe7-4aea-93c6-85434dcb1c5e"
esc <- tryCatch(
    read.csv("data/escapement.csv", stringsAsFactors = FALSE), #first thing we want to do
    error=function(cond) {  #if there is an error, do the following.  If no error, we skip
        message(paste(" Data file does not seem to exist, so get it from the KNB."))
        esc <- read.csv(url(data_url, method = "libcurl"), stringsAsFactors = FALSE)
        return(esc)
    }
)

head(esc)
```

Woot!  We have data, so let's make some maps.

```{r}
median_esc <- esc %>% 
  separate(sampleDate, c("Year", "Month", "Day"), sep = "-") %>% 
  group_by(Species, SASAP.Region, Year, Location) %>% 
  summarize(escapement = sum(DailyCount)) %>% 
  group_by(Species) %>% 
  summarize(median_escapement = median(escapement))

head(median_esc)
```

```{r}
ggplot(median_esc, aes(Species, median_escapement)) +
  geom_col() + #alternative to geom_bar?
  coord_flip()+theme_bw()
```

```{r}
locations <- esc %>% 
  distinct(Location, Latitude, Longitude) %>%   #removes duplicates, get list of distinct
  drop_na()  #how elegant!  Drops NA values
```

#Data tables are the bee's knees

Data table function create an interactive table!  the filter argument allows for sliders and search boxes to select data from each column.  Extensions allow for unlimited JS options see (https://datatables.net/extensions/index) for all the options!
```{r}
datatable(locations,
          filter='top',
          extensions = 'Buttons', 
          options = list(dom = 'Bfrtip',
    buttons = c('copy', 'csv', 'excel', 'pdf', 'print')
  ))
```

MAPS BABY!
```{r Map}
leaflet(locations) %>% 
  addTiles() %>% #pulls in google map for background
  addMarkers(~ Longitude, ~ Latitude, popup = ~ Location) #adds pins and describes what happens when you hover  # can we make hover show a table or a chart?  Pie chart of composition or something?
```


Whoops, we see that he sites in Russia should really be int he US.  We can use pipes to fix this and re-make our map!
```{r}
locs <- locations %>% mutate(Longitude = abs(Longitude) * -1)

leaflet(locs) %>% 
  addTiles() %>% 
  addMarkers(~ Longitude, ~ Latitude, popup = ~ Location)
```



```{r}
# Use a custom marker so Leaflet doesn't try to grab the marker images from 
# its CDN (this was brought up in 
# https://github.com/NCEAS/sasap-training/issues/22)
markerIcon <- makeIcon(
  iconUrl = "https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.3.1/images/marker-icon.png",
  iconWidth = 25, iconHeight = 41,
  iconAnchorX = 12, iconAnchorY = 41,
  shadowUrl = "https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.3.1/images/marker-shadow.png",
  shadowWidth = 41, shadowHeight = 41,
  shadowAnchorX = 13, shadowAnchorY = 41
)

leaflet(locs) %>% 
  addTiles() %>% 
  addMarkers(~ Longitude, ~ Latitude, popup = ~ Location, icon = markerIcon)
```

